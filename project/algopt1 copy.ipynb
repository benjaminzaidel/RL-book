{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"/Users/benjaminzaidel/Desktop/Kaggle/Forex_Pairs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_wide_dataframe(data_folder: str, limit_rows: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads all .txt files in `data_folder`, each containing\n",
    "    <DTYYYYMMDD>, <TIME>, <CLOSE>, etc. The resulting DataFrame\n",
    "    has:\n",
    "      - A 'time_step' column (int) formed by concatenating date/time (YYYYMMDDHHMMSS).\n",
    "      - One column per currency pair (derived from filename).\n",
    "      - Each cell is the <CLOSE> value for that (time_step, currency_pair).\n",
    "    \n",
    "    Only reads up to `limit_rows` from each file (if provided).\n",
    "\n",
    "    Then sorts rows by the first 8 digits of time_step (date),\n",
    "    and then by the remaining digits (time).\n",
    "    \"\"\"\n",
    "\n",
    "    dfs_for_merge = []\n",
    "\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(data_folder, filename)\n",
    "            \n",
    "            # 1) Optionally limit rows\n",
    "            if limit_rows is not None:\n",
    "                df = pd.read_csv(filepath, nrows=limit_rows)\n",
    "            else:\n",
    "                df = pd.read_csv(filepath)\n",
    "\n",
    "            required_cols = {\"<DTYYYYMMDD>\", \"<TIME>\", \"<CLOSE>\"}\n",
    "            if not required_cols.issubset(df.columns):\n",
    "                print(f\"Warning: Missing required columns in '{filename}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            df[\"time_step\"] = (\n",
    "                df[\"<DTYYYYMMDD>\"].astype(str) + df[\"<TIME>\"].astype(str)\n",
    "            ).astype(int)\n",
    "            \n",
    "            currency_pair = os.path.splitext(filename)[0]  # e.g. 'AUDJPY.txt' -> 'AUDJPY'\n",
    "\n",
    "            mini_df = df[[\"time_step\", \"<CLOSE>\"]].copy()\n",
    "            mini_df.rename(columns={\"<CLOSE>\": currency_pair}, inplace=True)\n",
    "            mini_df.set_index(\"time_step\", inplace=True)\n",
    "\n",
    "            dfs_for_merge.append(mini_df)\n",
    "\n",
    "    if not dfs_for_merge:\n",
    "        print(\"No valid data found or missing required columns.\")\n",
    "        return pd.DataFrame(columns=[\"time_step\"])\n",
    "\n",
    "    # 2) Merge all mini DataFrames side-by-side on time_step\n",
    "    df_wide = pd.concat(dfs_for_merge, axis=1)\n",
    "\n",
    "    df_wide.reset_index(inplace=True)\n",
    "\n",
    "    # 3) Sort by date/time\n",
    "    time_str = df_wide[\"time_step\"].astype(str)\n",
    "    date_part = time_str.str[:8].astype(int)\n",
    "    time_part = time_str.str[8:].astype(int)\n",
    "\n",
    "    df_wide[\"date_part\"] = date_part\n",
    "    df_wide[\"time_part\"] = time_part\n",
    "\n",
    "    df_wide.sort_values(by=[\"date_part\", \"time_part\"], inplace=True, ascending=[True, True])\n",
    "    df_wide.drop([\"date_part\", \"time_part\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "def build_rate_matrices(df_wide: pd.DataFrame) -> Tuple[List[np.ndarray], List[int]]:\n",
    "    \"\"\"\n",
    "    Convert each row of the wide df into an adjacency matrix.\n",
    "    Returns a list of matrices (one per row) and\n",
    "    the corresponding list of time_steps for reference.\n",
    "    \"\"\"\n",
    "    # 1) Identify all currency pairs\n",
    "    all_pairs = [col for col in df_wide.columns if col != \"time_step\"]\n",
    "    \n",
    "    # 2) Extract unique currencies\n",
    "    currency_set = set()\n",
    "    for pair in all_pairs:\n",
    "        base = pair[:3]\n",
    "        quote = pair[3:]\n",
    "        currency_set.add(base)\n",
    "        currency_set.add(quote)\n",
    "    currency_list = sorted(list(currency_set))\n",
    "    currency_to_idx = {cur: i for i, cur in enumerate(currency_list)}\n",
    "    \n",
    "    # 3) We'll build a list of adjacency matrices, one per row\n",
    "    rate_matrices = []\n",
    "    time_steps = []\n",
    "\n",
    "    for _, row in df_wide.iterrows():\n",
    "        # Initialize adjacency\n",
    "        n_c = len(currency_list)\n",
    "        mat = np.zeros((n_c, n_c), dtype=np.float32)\n",
    "        # set diagonal to 1.0\n",
    "        np.fill_diagonal(mat, 1.0)\n",
    "        \n",
    "        for pair in all_pairs:\n",
    "            rate = row[pair]\n",
    "            if pd.isna(rate):\n",
    "                continue\n",
    "            base = pair[:3]\n",
    "            quote = pair[3:]\n",
    "            \n",
    "            i = currency_to_idx[base]\n",
    "            j = currency_to_idx[quote]\n",
    "            \n",
    "            mat[i, j] = rate\n",
    "            \n",
    "            # if you also want to fill the reciprocal:\n",
    "            if rate != 0:\n",
    "                mat[j, i] = 1.0 / rate\n",
    "        \n",
    "        rate_matrices.append(mat)\n",
    "        time_steps.append(row[\"time_step\"])\n",
    "    \n",
    "    return rate_matrices, time_steps, currency_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class ForexTradingEnv(gym.Env):\n",
    "    def __init__(self, rate_matrices, currency_list, base_currency='USD'):\n",
    "        \"\"\"\n",
    "        :param rate_matrices: list of shape [n_c, n_c] adjacency matrices\n",
    "        :param currency_list: list of currency codes, e.g. ['AUD','CAD','CHF','EUR','GBP','JPY','NZD','USD',...]\n",
    "        :param base_currency: which currency we measure final PnL in\n",
    "        \"\"\"\n",
    "        super(ForexTradingEnv, self).__init__()\n",
    "        \n",
    "        self.rate_matrices = rate_matrices\n",
    "        self.currency_list = currency_list\n",
    "        self.n_c = len(currency_list)\n",
    "        \n",
    "        # Index of the base currency in currency_list\n",
    "        self.base_idx = currency_list.index(base_currency)\n",
    "        \n",
    "        self.num_steps = len(rate_matrices)\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # The agent's holdings in each currency\n",
    "        self.portfolio = np.zeros(self.n_c, dtype=np.float32)\n",
    "        self.portfolio[self.base_idx] = 1.0  # start with 1 unit of base currency only\n",
    "        \n",
    "        # Action space: choose from among n_c*n_c possible conversions i->j\n",
    "        self.action_space = spaces.Discrete(self.n_c * self.n_c)\n",
    "        \n",
    "        # Observation space: (n_c, n_c) matrix of exchange rates\n",
    "        # If you want the portfolio included, you can flatten or handle it differently:\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=np.inf,\n",
    "            shape=(self.n_c, self.n_c),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.portfolio[:] = 0\n",
    "        self.portfolio[self.base_idx] = 1.0  # start with 1 in base\n",
    "        return self._get_obs()\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        # Possibly just return the adjacency matrix.  If you also want to include\n",
    "        # the portfolio in the observation, you can flatten them together, e.g.:\n",
    "        # matrix_flat = self.rate_matrices[self.current_step].flatten()\n",
    "        # obs = np.concatenate([matrix_flat, self.portfolio], axis=0)\n",
    "        # But for now, we'll just return the matrix:\n",
    "        return self.rate_matrices[self.current_step]\n",
    "    \n",
    "def step(self, action):\n",
    "    i = action // self.n_c\n",
    "    j = action % self.n_c\n",
    "\n",
    "    current_matrix = self.rate_matrices[self.current_step]\n",
    "    old_val_base = self._value_in_base(current_matrix)\n",
    "\n",
    "    # Perform conversion\n",
    "    if i != j and current_matrix[i, j] > 0:\n",
    "        amount_i = self.portfolio[i]\n",
    "        if amount_i > 0:\n",
    "            self.portfolio[i] = 0.0\n",
    "            self.portfolio[j] += amount_i * current_matrix[i, j]\n",
    "\n",
    "    self.current_step += 1\n",
    "\n",
    "    # Check if we are at the end\n",
    "    done = (self.current_step >= self.num_steps)\n",
    "    reward = 0.0\n",
    "\n",
    "    if done:\n",
    "        # Final reward = final portfolio value - initial\n",
    "        final_val_base = self._value_in_base(current_matrix)\n",
    "        reward = final_val_base - 1.0\n",
    "        # Return a valid observation (e.g. the last one) so SB3 doesn't crash\n",
    "        return self.rate_matrices[-1], reward, done, {}\n",
    "    else:\n",
    "        # Compute incremental reward\n",
    "        new_matrix = self.rate_matrices[self.current_step]\n",
    "        new_val_base = self._value_in_base(new_matrix)\n",
    "        reward = new_val_base - old_val_base\n",
    "        return self.rate_matrices[self.current_step], reward, done, {}\n",
    "    \n",
    "        # inside ForexTradingEnv.step():\n",
    "    info = {\"portfolio\": self.portfolio.copy()}\n",
    "    return obs, reward, done, info\n",
    "\n",
    "\n",
    "    def _value_in_base(self, matrix):\n",
    "        \"\"\"\n",
    "        Convert the entire portfolio to base currency using the given adjacency matrix.\n",
    "        If rate=0 or NaN, treat it as unconvertible (skipped).\n",
    "        \"\"\"\n",
    "        total_base = 0.0\n",
    "        for c_idx, amt in enumerate(self.portfolio):\n",
    "            if c_idx == self.base_idx:\n",
    "                total_base += amt\n",
    "            else:\n",
    "                rate = matrix[c_idx, self.base_idx]\n",
    "                if rate > 0:\n",
    "                    total_base += amt * rate\n",
    "                else:\n",
    "                    # missing or invalid, treat as 0\n",
    "                    pass\n",
    "        return total_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random policy total reward: -2.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1) Build your wide DataFrame\n",
    "    df_wide = create_wide_dataframe(data_url, limit_rows=10000)\n",
    "    \n",
    "    # 2) Convert df_wide into adjacency matrices\n",
    "    rate_matrices, time_steps, currency_list = build_rate_matrices(df_wide)\n",
    "\n",
    "    # 3) Create environment\n",
    "    env = ForexTradingEnv(rate_matrices, currency_list, base_currency='USD')\n",
    "    \n",
    "    # 4) Quick random-policy run\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "    \n",
    "    print(\"Random policy total reward:\", total_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# 1) Create the wide DataFrame\n",
    "df_wide = create_wide_dataframe(data_url)\n",
    "\n",
    "# Optionally limit to the first 1000 rows for faster experiments:\n",
    "df_wide = df_wide.head(1000).copy()\n",
    "\n",
    "# 2) Convert df_wide to adjacency matrices\n",
    "rate_matrices, time_steps, currency_list = build_rate_matrices(df_wide)\n",
    "\n",
    "# 3) Create an instance of your environment\n",
    "env_instance = ForexTradingEnv(rate_matrices, currency_list, base_currency='USD')\n",
    "\n",
    "# 4) Wrap the environment in a DummyVecEnv so SB3 can handle it\n",
    "env = DummyVecEnv([lambda: env_instance])\n",
    "\n",
    "# 5) Instantiate a DQN model\n",
    "model = DQN(\n",
    "    policy=\"MlpPolicy\",    # Use a simple MLP\n",
    "    env=env,\n",
    "    learning_rate=1e-3,\n",
    "    buffer_size=50000,\n",
    "    batch_size=64,\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_final_eps=0.02,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./dqn_fx_log\"  # optional, for TensorBoard\n",
    ")\n",
    "\n",
    "# 6) Train the model\n",
    "model.learn(total_timesteps=10000)  # adjust as needed\n",
    "\n",
    "# 7) Evaluate or test the trained model\n",
    "obs = env.reset()\n",
    "done = False\n",
    "total_reward = 0.0\n",
    "\n",
    "while True:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    total_reward += reward[0]  # stable-baselines uses vectorized env, so reward is array-like\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"Total reward (deterministic) after training:\", total_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Suppose 'model' is your trained DQN and 'env' is your DummyVecEnv\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=5, render=False)\n",
    "\n",
    "print(f\"Evaluation over 5 episodes: mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def run_eval_episodes(model, env, num_episodes=5):\n",
    "    \"\"\"\n",
    "    Runs `num_episodes` episodes in the given vec-env (env),\n",
    "    always acting deterministically. Returns a list of total rewards.\n",
    "    \"\"\"\n",
    "    ep_rewards = []\n",
    "    \n",
    "    for e in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_r = 0.0\n",
    "        \n",
    "        while not done:\n",
    "            # model.predict() returns (action, state), we only need 'action'\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            \n",
    "            # because this is a vectorized env, reward is typically an array\n",
    "            total_r += reward[0]  \n",
    "        \n",
    "        ep_rewards.append(total_r)\n",
    "    \n",
    "    return ep_rewards\n",
    "\n",
    "\n",
    "# After model is trained:\n",
    "episode_rewards = run_eval_episodes(model, env, num_episodes=10)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(episode_rewards, marker='o')\n",
    "plt.title(\"Deterministic Policy Rewards over 10 Episodes\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval_with_portfolio(model, env, num_episodes=1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    portfolio_history = [env.envs[0].portfolio.copy()]  # for vectorized env\n",
    "    rewards_history = []\n",
    "    \n",
    "    total_r = 0.0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_r += reward[0]\n",
    "        # Grab the updated portfolio from info:\n",
    "        portfolio_history.append(info[0][\"portfolio\"].copy())\n",
    "        rewards_history.append(reward[0])\n",
    "    \n",
    "    return np.array(portfolio_history), rewards_history, total_r\n",
    "\n",
    "# Example usage, for 1 episode\n",
    "portfolio_hist, rewards_hist, final_r = run_eval_with_portfolio(model, env, num_episodes=1)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for c_idx, cur_name in enumerate(env.envs[0].currency_list):\n",
    "    plt.plot(portfolio_hist[:, c_idx], label=cur_name)\n",
    "plt.title(f\"Portfolio Holdings Over 1 Episode (Final Reward = {final_r:.2f})\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Amount Held\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALL_PYTHON",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
