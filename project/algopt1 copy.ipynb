{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"/Users/benjaminzaidel/Desktop/Kaggle/Forex_Pairs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_wide_dataframe(data_folder: str, limit_rows: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads all .txt files in `data_folder`, each containing\n",
    "    <DTYYYYMMDD>, <TIME>, <CLOSE>, etc. The resulting DataFrame\n",
    "    has:\n",
    "      - A 'time_step' column (int) formed by concatenating date/time (YYYYMMDDHHMMSS).\n",
    "      - One column per currency pair (derived from filename).\n",
    "      - Each cell is the <CLOSE> value for that (time_step, currency_pair).\n",
    "    \n",
    "    Only reads up to `limit_rows` from each file (if provided).\n",
    "\n",
    "    Then sorts rows by the first 8 digits of time_step (date),\n",
    "    and then by the remaining digits (time).\n",
    "    \"\"\"\n",
    "\n",
    "    dfs_for_merge = []\n",
    "\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(data_folder, filename)\n",
    "            \n",
    "            # 1) Optionally limit rows\n",
    "            if limit_rows is not None:\n",
    "                df = pd.read_csv(filepath, nrows=limit_rows)\n",
    "            else:\n",
    "                df = pd.read_csv(filepath)\n",
    "\n",
    "            required_cols = {\"<DTYYYYMMDD>\", \"<TIME>\", \"<CLOSE>\"}\n",
    "            if not required_cols.issubset(df.columns):\n",
    "                print(f\"Warning: Missing required columns in '{filename}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            df[\"time_step\"] = (\n",
    "                df[\"<DTYYYYMMDD>\"].astype(str) + df[\"<TIME>\"].astype(str)\n",
    "            ).astype(int)\n",
    "            \n",
    "            currency_pair = os.path.splitext(filename)[0]  # e.g. 'AUDJPY.txt' -> 'AUDJPY'\n",
    "\n",
    "            mini_df = df[[\"time_step\", \"<CLOSE>\"]].copy()\n",
    "            mini_df.rename(columns={\"<CLOSE>\": currency_pair}, inplace=True)\n",
    "            mini_df.set_index(\"time_step\", inplace=True)\n",
    "\n",
    "            dfs_for_merge.append(mini_df)\n",
    "\n",
    "    if not dfs_for_merge:\n",
    "        print(\"No valid data found or missing required columns.\")\n",
    "        return pd.DataFrame(columns=[\"time_step\"])\n",
    "\n",
    "    # 2) Merge all mini DataFrames side-by-side on time_step\n",
    "    df_wide = pd.concat(dfs_for_merge, axis=1)\n",
    "\n",
    "    df_wide.reset_index(inplace=True)\n",
    "\n",
    "    # 3) Sort by date/time\n",
    "    time_str = df_wide[\"time_step\"].astype(str)\n",
    "    date_part = time_str.str[:8].astype(int)\n",
    "    time_part = time_str.str[8:].astype(int)\n",
    "\n",
    "    df_wide[\"date_part\"] = date_part\n",
    "    df_wide[\"time_part\"] = time_part\n",
    "\n",
    "    df_wide.sort_values(by=[\"date_part\", \"time_part\"], inplace=True, ascending=[True, True])\n",
    "    df_wide.drop([\"date_part\", \"time_part\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "def build_rate_matrices(df_wide: pd.DataFrame) -> Tuple[List[np.ndarray], List[int]]:\n",
    "    \"\"\"\n",
    "    Convert each row of the wide df into an adjacency matrix.\n",
    "    Returns a list of matrices (one per row) and\n",
    "    the corresponding list of time_steps for reference.\n",
    "    \"\"\"\n",
    "    # 1) Identify all currency pairs\n",
    "    all_pairs = [col for col in df_wide.columns if col != \"time_step\"]\n",
    "    \n",
    "    # 2) Extract unique currencies\n",
    "    currency_set = set()\n",
    "    for pair in all_pairs:\n",
    "        base = pair[:3]\n",
    "        quote = pair[3:]\n",
    "        currency_set.add(base)\n",
    "        currency_set.add(quote)\n",
    "    currency_list = sorted(list(currency_set))\n",
    "    currency_to_idx = {cur: i for i, cur in enumerate(currency_list)}\n",
    "    \n",
    "    # 3) We'll build a list of adjacency matrices, one per row\n",
    "    rate_matrices = []\n",
    "    time_steps = []\n",
    "\n",
    "    for _, row in df_wide.iterrows():\n",
    "        # Initialize adjacency\n",
    "        n_c = len(currency_list)\n",
    "        mat = np.zeros((n_c, n_c), dtype=np.float32)\n",
    "        # set diagonal to 1.0\n",
    "        np.fill_diagonal(mat, 1.0)\n",
    "        \n",
    "        for pair in all_pairs:\n",
    "            rate = row[pair]\n",
    "            if pd.isna(rate):\n",
    "                continue\n",
    "            base = pair[:3]\n",
    "            quote = pair[3:]\n",
    "            \n",
    "            i = currency_to_idx[base]\n",
    "            j = currency_to_idx[quote]\n",
    "            \n",
    "            mat[i, j] = rate\n",
    "            \n",
    "            # if you also want to fill the reciprocal:\n",
    "            if rate > 0:\n",
    "                mat[i, j] = rate\n",
    "                mat[j, i] = 1 / rate\n",
    "            else:\n",
    "                mat[i, j] = 0\n",
    "                mat[j, i] = 0\n",
    "\n",
    "        \n",
    "        rate_matrices.append(mat)\n",
    "        time_steps.append(row[\"time_step\"])\n",
    "    \n",
    "    return rate_matrices, time_steps, currency_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "class ForexTradingEnv(gym.Env):\n",
    "    def __init__(self, rate_matrices, currency_list, base_currency='USD',\n",
    "                 max_steps_per_episode=1000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rate_matrices = rate_matrices\n",
    "        self.currency_list = currency_list\n",
    "        self.n_c = len(currency_list)\n",
    "        self.base_idx = currency_list.index(base_currency)\n",
    "        \n",
    "        self.num_steps = len(rate_matrices)\n",
    "        self.max_steps_per_episode = max_steps_per_episode\n",
    "        \n",
    "        # Portfolio\n",
    "        self.portfolio = np.zeros(self.n_c, dtype=np.float32)\n",
    "        \n",
    "        # Action space: choose i->j among n_c*n_c\n",
    "        self.action_space = spaces.Discrete(self.n_c * self.n_c)\n",
    "        \n",
    "        # Observation space: (n_c, n_c) adjacency matrix\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=np.inf,\n",
    "            shape=(self.n_c, self.n_c),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # For random window logic\n",
    "        self.current_step = 0\n",
    "        self.start_index = 0\n",
    "        self.end_index = 0\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"\n",
    "        Randomly pick a start index for each episode,\n",
    "        so we don't always begin at step=0.\n",
    "        \"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        # Random start: ensures we can sample different windows\n",
    "        if self.num_steps > self.max_steps_per_episode:\n",
    "            self.start_index = np.random.randint(\n",
    "                0, \n",
    "                self.num_steps - self.max_steps_per_episode\n",
    "            )\n",
    "        else:\n",
    "            # If dataset is smaller than max_steps_per_episode, just start at 0\n",
    "            self.start_index = 0\n",
    "        \n",
    "        self.end_index = self.start_index + self.max_steps_per_episode\n",
    "        self.current_step = self.start_index\n",
    "        \n",
    "        # Reset portfolio\n",
    "        self.portfolio[:] = 0.0\n",
    "        self.portfolio[self.base_idx] = 1.0\n",
    "        \n",
    "        obs = self._get_obs()\n",
    "        info = {}\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        i = action // self.n_c\n",
    "        j = action % self.n_c\n",
    "\n",
    "        current_matrix = self.rate_matrices[self.current_step]\n",
    "        old_val_base = self._value_in_base(current_matrix)\n",
    "        \n",
    "        # Optionally penalize no-trade or invalid trades:\n",
    "        # no_trade_penalty = -0.00001 if i == j or current_matrix[i,j] == 0 else 0.0\n",
    "        \n",
    "        # Perform currency conversion i->j if valid\n",
    "        if i != j and current_matrix[i, j] > 0:\n",
    "            amount_i = self.portfolio[i]\n",
    "            if amount_i > 0:\n",
    "                self.portfolio[i] = 0.0\n",
    "                self.portfolio[j] += amount_i * current_matrix[i, j]\n",
    "        \n",
    "        self.current_step += 1\n",
    "        \n",
    "        # Episode ends if we reach end_index or run out of data\n",
    "        terminated = (self.current_step >= self.end_index) or (self.current_step >= self.num_steps)\n",
    "        truncated = False\n",
    "        \n",
    "        if terminated:\n",
    "            # Final reward: final base value - 1.0\n",
    "            final_val_base = self._value_in_base(current_matrix)\n",
    "            reward = final_val_base - 1.0\n",
    "            obs = self.rate_matrices[-1]  # valid final obs\n",
    "        else:\n",
    "            # Step reward = delta in base currency\n",
    "            new_matrix = self.rate_matrices[self.current_step]\n",
    "            new_val_base = self._value_in_base(new_matrix)\n",
    "            reward = new_val_base - old_val_base\n",
    "            \n",
    "            # If you want to add the no-trade penalty:\n",
    "            # reward += no_trade_penalty\n",
    "            \n",
    "            obs = self.rate_matrices[self.current_step]\n",
    "        \n",
    "        info = {}\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return self.rate_matrices[self.current_step]\n",
    "\n",
    "    def _value_in_base(self, matrix):\n",
    "        total_base = 0.0\n",
    "        for c_idx, amt in enumerate(self.portfolio):\n",
    "            if c_idx == self.base_idx:\n",
    "                total_base += amt\n",
    "            else:\n",
    "                rate = matrix[c_idx, self.base_idx]\n",
    "                if rate > 0:\n",
    "                    total_base += amt * rate\n",
    "        return total_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminzaidel/opt/anaconda3/envs/ALL_PYTHON/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:77: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1170     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0416   |\n",
      "|    n_updates        | 974      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1126     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 1974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1096     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1073     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0408   |\n",
      "|    n_updates        | 3974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1063     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0641   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1037     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1031     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0531   |\n",
      "|    n_updates        | 6974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1034     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.085    |\n",
      "|    n_updates        | 7974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1034     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0721   |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.604    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1036     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1014     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0426   |\n",
      "|    n_updates        | 10974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1010     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 999      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 52000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0531   |\n",
      "|    n_updates        | 12974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 986      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 56000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0443   |\n",
      "|    n_updates        | 13974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 969      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0694   |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 64000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0562   |\n",
      "|    n_updates        | 15974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 68000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0817   |\n",
      "|    n_updates        | 16974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.287    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0503   |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.248    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 76000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0685   |\n",
      "|    n_updates        | 18974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0362   |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0794   |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.129    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 88000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 21974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0892   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 945      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 92000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0298   |\n",
      "|    n_updates        | 22974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0496   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 933      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 96000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.073    |\n",
      "|    n_updates        | 23974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 928      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0463   |\n",
      "|    n_updates        | 24974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 922      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 104000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.169    |\n",
      "|    n_updates        | 25974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 922      |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 108000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0939   |\n",
      "|    n_updates        | 26974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 922      |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 112000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0675   |\n",
      "|    n_updates        | 27974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 923      |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 116000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0348   |\n",
      "|    n_updates        | 28974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 924      |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0979   |\n",
      "|    n_updates        | 29974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 924      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 124000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0482   |\n",
      "|    n_updates        | 30974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 924      |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 128000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 31974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 924      |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 132000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0448   |\n",
      "|    n_updates        | 32974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 925      |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 136000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0347   |\n",
      "|    n_updates        | 33974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 925      |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 140000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0465   |\n",
      "|    n_updates        | 34974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 925      |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 144000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.064    |\n",
      "|    n_updates        | 35974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 925      |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 148000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0307   |\n",
      "|    n_updates        | 36974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 925      |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 152000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0487   |\n",
      "|    n_updates        | 37974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 926      |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 156000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0543   |\n",
      "|    n_updates        | 38974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 926      |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0705   |\n",
      "|    n_updates        | 39974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 926      |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 164000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0462   |\n",
      "|    n_updates        | 40974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 926      |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 168000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 41974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 926      |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 172000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0654   |\n",
      "|    n_updates        | 42974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 926      |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 176000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 43974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 922      |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 180000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0647   |\n",
      "|    n_updates        | 44974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 916      |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 184000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0732   |\n",
      "|    n_updates        | 45974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 911      |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 188000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 46974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 908      |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 192000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 47974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 196000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0769   |\n",
      "|    n_updates        | 48974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0857   |\n",
      "|    n_updates        | 49974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 204000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.043    |\n",
      "|    n_updates        | 50974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 208000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 51974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 212000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0824   |\n",
      "|    n_updates        | 52974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 216000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 53974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 220000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0842   |\n",
      "|    n_updates        | 54974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 224000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0958   |\n",
      "|    n_updates        | 55974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 228000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 56974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 232000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0579   |\n",
      "|    n_updates        | 57974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 236000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0345   |\n",
      "|    n_updates        | 58974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 240000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0338   |\n",
      "|    n_updates        | 59974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 244000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0767   |\n",
      "|    n_updates        | 60974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 248000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0363   |\n",
      "|    n_updates        | 61974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 252000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0729   |\n",
      "|    n_updates        | 62974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 256000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.058    |\n",
      "|    n_updates        | 63974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 260000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0598   |\n",
      "|    n_updates        | 64974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 264000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0825   |\n",
      "|    n_updates        | 65974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 268000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0399   |\n",
      "|    n_updates        | 66974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 272000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0543   |\n",
      "|    n_updates        | 67974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 903      |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 276000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0556   |\n",
      "|    n_updates        | 68974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 280000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 69974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 284000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0348   |\n",
      "|    n_updates        | 70974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 288000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0496   |\n",
      "|    n_updates        | 71974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 292000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 72974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 296000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 73974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 300000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0757   |\n",
      "|    n_updates        | 74974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 304000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 75974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 308000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0746   |\n",
      "|    n_updates        | 76974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 312000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0528   |\n",
      "|    n_updates        | 77974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 316000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0556   |\n",
      "|    n_updates        | 78974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 320000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 79974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 324000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0937   |\n",
      "|    n_updates        | 80974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 328000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 81974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 897      |\n",
      "|    time_elapsed     | 370      |\n",
      "|    total_timesteps  | 332000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0322   |\n",
      "|    n_updates        | 82974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 375      |\n",
      "|    total_timesteps  | 336000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0726   |\n",
      "|    n_updates        | 83974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 379      |\n",
      "|    total_timesteps  | 340000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0809   |\n",
      "|    n_updates        | 84974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 384      |\n",
      "|    total_timesteps  | 344000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0925   |\n",
      "|    n_updates        | 85974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 388      |\n",
      "|    total_timesteps  | 348000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0864   |\n",
      "|    n_updates        | 86974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 393      |\n",
      "|    total_timesteps  | 352000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.032    |\n",
      "|    n_updates        | 87974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 397      |\n",
      "|    total_timesteps  | 356000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 88974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 402      |\n",
      "|    total_timesteps  | 360000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0518   |\n",
      "|    n_updates        | 89974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 407      |\n",
      "|    total_timesteps  | 364000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0456   |\n",
      "|    n_updates        | 90974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 411      |\n",
      "|    total_timesteps  | 368000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0783   |\n",
      "|    n_updates        | 91974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 416      |\n",
      "|    total_timesteps  | 372000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0633   |\n",
      "|    n_updates        | 92974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 420      |\n",
      "|    total_timesteps  | 376000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 93974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 425      |\n",
      "|    total_timesteps  | 380000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0468   |\n",
      "|    n_updates        | 94974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 892      |\n",
      "|    time_elapsed     | 430      |\n",
      "|    total_timesteps  | 384000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 95974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 889      |\n",
      "|    time_elapsed     | 436      |\n",
      "|    total_timesteps  | 388000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.049    |\n",
      "|    n_updates        | 96974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 886      |\n",
      "|    time_elapsed     | 441      |\n",
      "|    total_timesteps  | 392000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0492   |\n",
      "|    n_updates        | 97974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 884      |\n",
      "|    time_elapsed     | 447      |\n",
      "|    total_timesteps  | 396000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 98974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 882      |\n",
      "|    time_elapsed     | 453      |\n",
      "|    total_timesteps  | 400000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.056    |\n",
      "|    n_updates        | 99974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 882      |\n",
      "|    time_elapsed     | 457      |\n",
      "|    total_timesteps  | 404000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0394   |\n",
      "|    n_updates        | 100974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 462      |\n",
      "|    total_timesteps  | 408000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0497   |\n",
      "|    n_updates        | 101974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 467      |\n",
      "|    total_timesteps  | 412000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 102974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 880      |\n",
      "|    time_elapsed     | 472      |\n",
      "|    total_timesteps  | 416000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0532   |\n",
      "|    n_updates        | 103974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 477      |\n",
      "|    total_timesteps  | 420000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 104974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 482      |\n",
      "|    total_timesteps  | 424000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0463   |\n",
      "|    n_updates        | 105974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 877      |\n",
      "|    time_elapsed     | 487      |\n",
      "|    total_timesteps  | 428000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0767   |\n",
      "|    n_updates        | 106974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 875      |\n",
      "|    time_elapsed     | 493      |\n",
      "|    total_timesteps  | 432000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.098    |\n",
      "|    n_updates        | 107974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 498      |\n",
      "|    total_timesteps  | 436000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0323   |\n",
      "|    n_updates        | 108974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 503      |\n",
      "|    total_timesteps  | 440000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 109974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 509      |\n",
      "|    total_timesteps  | 444000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0468   |\n",
      "|    n_updates        | 110974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 513      |\n",
      "|    total_timesteps  | 448000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0637   |\n",
      "|    n_updates        | 111974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 518      |\n",
      "|    total_timesteps  | 452000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0272   |\n",
      "|    n_updates        | 112974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 522      |\n",
      "|    total_timesteps  | 456000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0587   |\n",
      "|    n_updates        | 113974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 526      |\n",
      "|    total_timesteps  | 460000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 114974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 531      |\n",
      "|    total_timesteps  | 464000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0369   |\n",
      "|    n_updates        | 115974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 536      |\n",
      "|    total_timesteps  | 468000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0449   |\n",
      "|    n_updates        | 116974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 541      |\n",
      "|    total_timesteps  | 472000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 117974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 546      |\n",
      "|    total_timesteps  | 476000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0426   |\n",
      "|    n_updates        | 118974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 869      |\n",
      "|    time_elapsed     | 551      |\n",
      "|    total_timesteps  | 480000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0605   |\n",
      "|    n_updates        | 119974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 868      |\n",
      "|    time_elapsed     | 557      |\n",
      "|    total_timesteps  | 484000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0431   |\n",
      "|    n_updates        | 120974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 562      |\n",
      "|    total_timesteps  | 488000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.027    |\n",
      "|    n_updates        | 121974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 567      |\n",
      "|    total_timesteps  | 492000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0411   |\n",
      "|    n_updates        | 122974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 572      |\n",
      "|    total_timesteps  | 496000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0475   |\n",
      "|    n_updates        | 123974   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 576      |\n",
      "|    total_timesteps  | 500000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0465   |\n",
      "|    n_updates        | 124974   |\n",
      "----------------------------------\n",
      "Episode Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013894081115722656]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt3UlEQVR4nO3de5xcVZnv/883nfuFAAGCJIEEEqLBUYEAzqBjjtEBxkv4KRyio8N4GDmeAcW74AUdlDM6Z0bEAyoZ4IjoAMowmDNmwKPQKI7cQRgu3WlDMAl0J4EkVOfeyfP7Y69KVxd9qe70rurq/r5fr35l19577f3USnU9vddae21FBGZmZpUaVesAzMysvjhxmJlZvzhxmJlZvzhxmJlZvzhxmJlZvzhxmJlZvzhxDBGS2iUdPQjH+YqkHw5GTGXHPTLF2DDIx10t6W2DecyhRFKjpL8eYNnfSDp+sGOqFklvltQ02Pt2U/bfJZ07kLIDPF9ImpuWvyfpS/t5vH+U9D8GJ7rqcOKosvRFuT19CRd/joiIyRGxKudzL5K0t+zc7ZL+uK+yEfGHFOOePGOsVNl7KUhqkvShWsc1WCS9CyhExKPp9Vck7U7vtSCpWdJVkl7Vj2NWNUlHxK8jYv5g7tvdH0YRcUZE3NDf+FIC2Jo+Q+skfbO/fxhFxEci4qv9PXeZfwA+L2nsfh6napw4auNd6Uu4+PN8Fc/9fNm5J0fEb6t4/sH0fERMBg4APgH8k6SKvqgGmzKD+fv0EeDGsnW3RMQU4GDg/wMOBx7uT/IYqBze31Dx+vQZWgy8H/hwtQOIiBeAZ4B3V/vcAzUcPwh1qezy9/uSrpb0s/TX5f2SjinZ90pJayS9LOlhSW8epBgaJf2dpAfSsX8q6eC0bXaKcXR6/VeSVqX4npX0F2n9KElflPScpPWSfiBpask5Ppi2vSjpC2XnHyXpYkm/T9t/XDx/byKzAngJeF1fx5J0g6RPpeUZ6X1dkF4fI+mlVP4gSf8maYOkTWl5Zll9XS7pN8A24GhJb5f0jKQtkq4CVLL/XEn3pG0bJd3Sw//DWOCtwD09vN/dEfEkcA6wAfhUSdl3SnpM0mZJ/yGpWB83AkcC/zf9hf3ZtP6Nab/Nkn4naVEf7y8k/Y2klen//qupzv4jfWZ+XPzLWdlV4dqS462W9GlJj6c6uEXS+B72/Zyyq4Di1eRiSacDnwfOSe/hdyVx/nVJ2Q9LejqVfUrSCd3VY1mdPgP8GnhtyTFa0mdhuaQjevi/+r6kr5W8XpLq/+X02Ttd0tmSHi4r90lJPy1Z1Qi8o684h4yI8E8Vf4DVwNu6WR/A3LT8feBF4GRgNPAj4OaSfT8ATEvbPgW0AuPTtq8AP+zh3IuAtb3E1gisI/vlmQT8S/FYwOwU4+i07WVgftr2KuC4tPzfgBbgaGAycBtwY9q2AGgH/hQYB3wT6CjWB3ARcB8wM22/Bripr/dC9gfQu4G9wPF9HSvF+H/T8vuB35P9NV/c9tO0PA14LzARmAL8BLi9rL7+AByX6uVQoACcBYwhuwrqAP467X8T8IUU73jgTT28t+OArWXruv1/BS4D7k/LxwPrgVOABuBcss/buO4+e8AMss/Zn6eY3p5eH9rD+xuTPgM/JbvKOw7YCfwy/X9PBZ4Czu3u85bO/wBwBNlV09PAR7r5/5wPrAGOKPnsHdNTPaQ4i3V8Ntln+CSypD0XOKqHei79nVtA9nt0HlnS3gicQPbZ+d/Ar3r5Xf1aWj4Z2JLqcVSq31enY7wEvKbkGI8C7y15/R7gkVp/P1X8PVbrAEbaT/rlaQc2p5/b0/ryD+O1JWX+HHiml2NuIrvk7vYXq2S/RWRfrpvLfial7Y3A10v2XwDsIvsSmk3XxLGZ7Et1Qtk5fgn8Tcnr+cDuVO5SuibASen4xcTxNLC4ZPurimX7eC87gT3Ax0u293gs4JhUZ6OA7wH/nc4vrRuAT/ZQf28ANpW8bgQuK3n9l8B9Ja8FrKXzS+0HwDJgZh+fkVOB1rJ13f6/kjVprUzL3wW+Wra9CXhLyWevNHF8jpTUS9bdSecXf5f3V/I5PbXk9cPA50pe/yPwrZL/o/LE8YGS138PfK98X7Iv+/XA24AxfdUDXRPHncBFFf4uBtkfQJvI/nj4WvpMXAf8fcl+k9NnZ3YPv6vFxHENcEUP5/oucHlaPi6dc1zJ9rcDqyqJeyj8uKmqNs6MiAPTz5k97NNasryN7MMLQLrcfzpd7m8m+0vvkArP/XzJuYs/W0u2rylZfo7sr8wux077n0P2pfWCsia1V6fNR6RypccYDUxP29aUHefFkn2PAv41NZtsJvvy35PK9vheyP76/TbZX4p9Hisifg9sJUsEbwb+DXheWf/IW0hNRJImSrpGWdPay8CvgAPVtQO1tL7K31+Ubf8sWTJ5QNKTkv5bD+9rE9kVTiVmkP01W3zPnyq+5/S+Z6W4unMUcHbZ/m8iS7JFa7op11ayvL2b15PpWY+f66KIaAE+TpYk1ku6uaemom7MIksClTohIg6KiGMi4osRsZeyz3BEtJN9Tmfsx7lvAN4vScAHgR9HxM6S7VPI/giqC04cdUZZf8Zngf8KHJS+OLdQ0pa+n2aVLB9J9pfWxvKdIuLOiHg72ZfMM8A/pU3Pk30hlR6jg+zL5YXS40uaSNYcVLQGOKMsqY2PiHW9BZx+AT8H/JGkMys81j1kTUpj07p7yJp2DgIeS/t8iuyK6ZSIOICsiQ261nXp9NLl70+lryOiNSI+HBFHkF3lfEepX6tMSyre6xeVss7qd5G1zRff8+Vl73liRNzUTazF/W8s239SRHy9h/dXNRHxzxHxJrLPUgDfqDCeNWRXlPujy2dY0iSyz2mvn8Pezh0R95FdXb+ZrHm0fODDa4DfDTDeqnPiqD9TyL6INwCjJV1K9hf3YPmApAXpS/0y4NYoG4IraXrqBJxE1kzUTtZsBFk7/ickzZE0GfifZP0HHcCtwDslvSl1oF5G18/g94DLJR2VznOopCWVBB0Ru8iaSS6t8Fj3ABeSXUVA1txxIXBvyfudQvYX9GZlHetf7iOMnwHHSXqPskEEHyMb+USK4Wx1dq5vIvsS3Ft+kPRefkF29fMKkkZLeg1ZXR9O1lcEWfL+iKRTlJkk6R2SilcvbWR9EUU/BN4l6TRJDZLGp07qmdSQpPmS3ippHLCD7P+gWE9twGz1PMLrWuDTkk5MdTC3+Bnoh5uAD0l6Q4rhf5L1I63uo9x1qdxiZYMrZpRciUPWVHkVsDsi7i0r+xbg3/sZZ804cdSfO4E7gGayy+kddN+c0JMj9Mr7ON5bsv1GsnbbVrIO3I91c4xRwCfJ/jJ7iexDX7yB6fp0jF8Bz6b4PgoQ2UigC4B/JvvrfBNZH0DRlcBy4OeSCmSd26f0471dDxyp7B6Ivo51D1liKCaOe8k6wX9Vss+3gAlkV1z3kdV7jyJiI1nn7NfJmjbmAb8p2eUk4H5J7Sm2i6Lne3euIWvSKHVOKrsllX8RODHScO6IeIhsOOlVZHXbAvxVSfm/A76YmqU+HRFrgCVkI5U2kH2OPkPtvxfGkdXhRrLP4WHAJWnbT9K/L0p6pLxgRPwEuJzsM1YAbifriK9YRPwC+BLZ4JAXyK4illZQ7gHgQ8AVZP9H99D16vtGsoEnXe5DUTacekGKtS4odcyYIamRrOPx2lrHYtmd48CFkW4CtPomaQJZp/8JEbGyZP0/Ar+PiO/ULLh+Gl3rAMysexFxaq1jsEH1P4AHS5MGQER8qof9hywnDjOznElaTTao4szaRjI43FRlZmb9UutOMDMzqzMjoqnqkEMOidmzZw+o7NatW5k0adLgBlTHXB+dXBdduT46DZe6ePjhhzdGxKHl60dE4pg9ezYPPfTQgMo2NjayaNGiwQ2ojrk+OrkuunJ9dBoudSHpue7Wu6nKzMz6xYnDzMz6xYnDzMz6xYnDzMz6JdfEkZ5+1aTsSVoXd7N9nLKngLUoe8rd7LR+mqS70zxKV/Vw7OWS/jPP+M3M7JVyG1WVnllwNdkDStYCD0paHhFPlex2HtmDceZKWko2dfI5ZBPjfYlsQrDXdnPs95DNyGpmZmVuf3Qd/+vOJp7fvJ0jDpzAZ06bz5nH9/U4kcrlecVxMtASEavSNNE3k83EWWoJ2QNOIJtye7EkRcTWNO3wjvKDpqm6P0n2tC4zMytx+6PruOS2J1i3eTsBrNu8nUtue4LbH+3rcSKVy/M+jhl0ne57La+cInvfPhHRIWkL2QNTXvHgoBJfJXvuwrbeTi7pfOB8gOnTp9PY2Nif2Pdpb28fcNnhyPXRyXXRleujUy3r4quN29i+u+tUUtt37+GrP/0dB25Z2UOp/qmrGwAlvYHsofWfKPaH9CQilpE935mFCxfGQG/GGS438gwW10cn10VXro9OtayLl+74Wffrd8SgxZRnU9U6uj6GdCavfPTivn3SE9Om0vUZ1OX+GFiYZpq8Fzg2PUPCzMyAIw6c0K/1A5Fn4ngQmJceITqW7Alay8v2WU72nGfInv98V/QyXW9EfDcijoiI2cCbgOaIWDTokZuZ1anPnDafCWMauqybMKaBz5w2f9DOkVtTVeqzuJDsUacNwPUR8aSky4CHImI52TN6b5TUQvYI0n2PZ0xXFQcAYyWdCfxZ2YgsMzMrc+bxM9i5ew+fu+0JAGbkMKoq1z6OiFgBrChbd2nJ8g6yZzR3V3Z2H8deTTdDdc3MRrr5rzoAgGs+eCKnHXf4oB/fd46bmQ0zza0FAOZPn5LL8Z04zMyGmea2AuNGj2LWwRNzOb4Th5nZMNPUVmDe9Mk0jFIux3fiMDMbZprbChybUzMVOHGYmQ0rm7ftou3lnbn1b4ATh5nZsNLcls3/euzhThxmZlaB5rZsRJWbqszMrCLNbQUmjxvNEVPH53YOJw4zs2GkqbXAsdMnI+UzogqcOMzMho2IoLmtwPwc+zfAicPMbNjY0L6TTdt259q/AU4cZmbDxsriiConDjMzq0RTa/4jqsCJw8xs2GhuK3DwpLEcMnlsrudx4jAzGyaa2vIfUQVOHGZmw0JEsLKtPfdmKnDiMDMbFp7fsoP2nR1OHGZmVpl9D2/K+R4OcOIwMxsWmopzVB1W54lD0umSmiS1SLq4m+3jJN2Stt8vaXZaP03S3ZLaJV1Vsv9EST+T9IykJyV9Pc/4zczqRXNrgcMPGM/UiWNyP1duiUNSA3A1cAawAHifpAVlu50HbIqIucAVwDfS+h3Al4BPd3Pof4iIVwPHA6dKOiOP+M3M6knxqX/VkOcVx8lAS0SsiohdwM3AkrJ9lgA3pOVbgcWSFBFbI+JesgSyT0Rsi4i70/Iu4BFgZo7vwcxsyNuzN2hZ357rw5tKjc7x2DOANSWv1wKn9LRPRHRI2gJMAzb2dXBJBwLvAq7sYfv5wPkA06dPp7GxsX/RJ+3t7QMuOxy5Pjq5LrpyfXSqdl20bt3Lzo69xOZ1NDauz/18eSaO3EgaDdwEfDsiVnW3T0QsA5YBLFy4MBYtWjSgczU2NjLQssOR66OT66Ir10enatfFHf/ZCr9+mHe/5SReP+vA3M+XZ1PVOmBWyeuZaV23+6RkMBV4sYJjLwNWRsS39j9MM7P6Vnzq33Do43gQmCdpjqSxwFJgedk+y4Fz0/JZwF0REb0dVNLXyBLMxwc3XDOz+tTUVmDWwROYOLY6jUi5nSX1WVwI3Ak0ANdHxJOSLgMeiojlwHXAjZJagJfIkgsAklYDBwBjJZ0J/BnwMvAF4BngkTQfy1URcW1e78PMbKhb2VaoWsc45NzHERErgBVl6y4tWd4BnN1D2dk9HDbf2bvMzOrIro69rNqwlbe9ZnrVzuk7x83M6tizG7fSsTeqMtVIkROHmVkd2zfVSBWbqpw4zMzq2Mq2Ag2jxNGHTqraOZ04zMzqWFNrgdnTJjJudEPVzunEYWZWx5rbClXt3wAnDjOzurV91x6ee2lbVfs3wInDzKxutaxvJ4Kq3sMBThxmZnWrc6oRJw4zM6tAc1uBsQ2jmD1tYlXP68RhZlanmtoKHHPYZEY3VPer3InDzKxONbcWmF+lGXFLOXGYmdWhl3fs5vktOzi2ykNxwYnDzKwurWxrB+DYw5w4zMysAsURVdW++Q+cOMzM6lJTa4GJYxuYceCEqp/bicPMrA41txWYN30Ko0ZV/xFFThxmZnWoua02I6rAicPMrO682L6Tje27qj5HVZETh5lZnWkujqgajolD0umSmiS1SLq4m+3jJN2Stt8vaXZaP03S3ZLaJV1VVuZESU+kMt+W5GeQm9mIUssRVZBj4pDUAFwNnAEsAN4naUHZbucBmyJiLnAF8I20fgfwJeDT3Rz6u8CHgXnp5/TBj97MbOhqaiswdcIYDpsyribnz/OK42SgJSJWRcQu4GZgSdk+S4Ab0vKtwGJJioitEXEvWQLZR9KrgAMi4r6ICOAHwJk5vgczsyEnm2pkCrVqcMkzccwA1pS8XpvWdbtPRHQAW4BpfRxzbR/HNDMbtiIiDcWtzYgqgNE1O3POJJ0PnA8wffp0GhsbB3Sc9vb2AZcdjlwfnVwXXbk+OuVZF5t27OXlHR3o5VYaG1/M5Rx9yTNxrANmlbyemdZ1t89aSaOBqUBvNbEuHae3YwIQEcuAZQALFy6MRYsW9Sf2fRobGxlo2eHI9dHJddGV66NTnnVxT/MGaHyAd775BN54dG8NNPnJs6nqQWCepDmSxgJLgeVl+ywHzk3LZwF3pb6LbkXEC8DLkt6YRlP9JfDTwQ/dzGxoam7NRlTVaigu5HjFEREdki4E7gQagOsj4klJlwEPRcRy4DrgRkktwEtkyQUASauBA4Cxks4E/iwingL+Bvg+MAH49/RjZjYiNLUVOHTKOA6eNLZmMeTaxxERK4AVZesuLVneAZzdQ9nZPax/CHjt4EVpZlY/VrYVOLaGHePgO8fNzOrG3r1Bc1t7TZupwInDzKxurN20ne279zDficPMzCrRlKYaqcXjYks5cZiZ1YniHFXzDnMfh5mZVaC5rcCMAycwZfyYmsbhxGFmVieaWms/ogqcOMzM6sLuPXtZtWFrzfs3wInDzKwuPPfiVnbt2VvzEVXgxGFmVhdq/dS/Uj3eOS7pk70VjIhvDn44ZmbWnabWAqMEc2s8ogp6n3KkmNbmAyfROUHhu4AH8gzKzMy6am4rcNS0SYwf01DrUHpOHBHxtwCSfgWcEBGF9PorwM+qEp2ZmQHZzX9DYUQVVNbHMR3YVfJ6V1pnZmZVsGP3HlZv3DokOsahstlxfwA8IOlf0+szyaY1NzOzKli1YSt7o/ZTjRT1mjjSw5J+QPbMizen1R+KiEfzDszMzDLFqUaGwogq6CNxRERIWhERfwQ8UqWYzMysRFNbgTENYva0SbUOBaisj+MRSSflHomZmXWrubXA0YdMZuzooXHrXSV9HKcAfyHpOWArILKLkdflGpmZmQHZFcfxRx5U6zD2qSRxnJZ7FGZm1q2tOztYu2k7S0+aVetQ9ukzcUTEcwCSDgPG5x6RmZnts3J9NtXIvCHSMQ4V9HFIereklcCzwD3AarJRVn2SdLqkJkktki7uZvs4Sbek7fdLml2y7ZK0vknSaSXrPyHpSUn/KekmSU5mZjZsNbdmI6qGyj0cUFnn+FeBNwLNETEHWAzc11chSQ3A1cAZwALgfZIWlO12HrApIuYCVwDfSGUXAEuB44DTge9IapA0A/gYsDAiXgs0pP3MzIalprYC48eMYtbBE2sdyj6VJI7dEfEiMErSqIi4G1hYQbmTgZaIWBURu4CbgSVl+ywBbkjLtwKL070jS4CbI2JnRDwLtKTjQda8NkHSaGAi8HwFsZiZ1aXmtgLzDptCwyjVOpR9Kukc3yxpMvAr4EeS1pONrurLDGBNyeu1ZCO0ut0nIjokbQGmpfX3lZWdERG/lfQPwB+A7cDPI+Ln3Z1c0vnA+QDTp0+nsbGxgpBfqb29fcBlhyPXRyfXRVeuj06DWRdP/GEbx01rGFJ1W0niWEL2Jf0J4C+AqcBleQbVE0kHpXjmAJuBn0j6QET8sHzfiFgGLANYuHBhLFq0aEDnbGxsZKBlhyPXRyfXRVeuj06DVRebt+1i8x3/jz99/VwWveWY/Q9skFTSVLUUOCYiOiLihoj4dmq66ss6oHT82My0rtt9UtPTVODFXsq+DXg2IjZExG7gNuBPKojFzKzu7Ht40xCZo6qoksRxJHCNpGcl/UTSRyW9oYJyDwLzJM2RNJYsAS0v22c5cG5aPgu4KyIirV+aRl3NAeaRPQPkD8AbJU1MfSGLgacriMXMrO40tQ29EVVQ2X0cXwaQNAH4MPAZ4FtkI5p6K9ch6ULgzrTv9RHxpKTLgIciYjlwHXCjpBbgJdIIqbTfj4GngA7ggojYA9wv6VayebM6gEdJzVFmZsNNc2uBKeNG86qpQ+uugz4Th6QvAqcCk8m+qD8N/LqSg0fECmBF2bpLS5Z3AGf3UPZy4PJu1n8Z+HIl5zczq2fNbQWOPXwKWQPL0FFJU9V7yEY6/YKsT+GnEfFCrlGZmY1wEZEljiHy1L9SfSaOiDiBrFP6AeDtwBOS7s07MDOzkWxD+042bds9ZJ7BUaqSpqrXkj3E6S1kN/6tocKmKjMzG5jm1mxE1VDrGIfK7uP4Olmi+DbwYBoGa2ZmOSqOqBpqQ3GhslFV70wjqo500jAzq46VbQUOnjSWQyaPq3Uor1DJ7LjvAh4D7kiv3yCp/H4MMzMbRE1DtGMcKhtV9RWyCQY3A0TEY2RTfpiZWQ4igubWwpDs34DKZ8fdUrYu8gjGzMxg3ebtbN21Z0j2b0BlneNPSno/0CBpHtnzMP4j37DMzEau5iE61UhRJVccHyV7oNJO4CZgC3BRnkGZmY1kxckNh9LjYktVcgPgtoj4QkScFBELgRuBq/IPzcxsZGpuLXD4AeOZOmFMrUPpVo+JQ9LrJP08Pdv7a5JeJelfgF+STT5oZmY5aEpzVA1VvV1x/BPwz8B7gY1kQ3J/D8yNiCvyD83MbOTZszdoWd/O/CE6FBd67xwfFxHfT8tNkj4WEZ+tQkxmZiPWH17axs6OvUNyjqqi3hLHeEnHA8X5fHeWvo6IR/IOzsxspGlqTVON1GnieAH4Zsnr1pLXAbw1r6DMzEaq4lDcefXYVBUR/6WagZiZWdYxfuTBE5k4tpLb7Gqjkvs4zMysSppbC0O6mQqcOMzMhoxdHXt5duNW5h8+dJupIOfEIel0SU2SWiRd3M32cZJuSdvvlzS7ZNslaX2TpNNK1h8o6VZJz0h6WtIf5/kezMyq5dmNW+nYG0P+iqPHRjRJJ/RWsK9RVZIagKvJHje7FnhQ0vKIKL158DxgU0TMlbQU+AZwjqQFwFKyqU6OAH4h6diI2ANcCdwREWdJGgtM7PNdmpnVgX0Pb6rXxAH8Yy/bKhlVdTLQEhGrACTdDCyh613nS8imbQe4FbhKktL6myNiJ/CspBbgZElPAX8K/BVAROwCdvURh5lZXWhuLdAwShx96KRah9KrPEdVzSB7PnnRWuCUnvaJiA5JW4Bpaf19ZWVnANuBDcD/kfR64GHgoojYup+xmpnVXFNbgTmHTGLc6IZah9KrisZ7SXotsAAYX1wXET/IK6hejAZOAD4aEfdLuhK4GPhS+Y6SzgfOB5g+fTqNjY0DOmF7e/uAyw5Hro9OrouuXB+dBloXj6/expEHjBry9dhn4pD0ZWARWeJYAZwB3Av0lTjWAbNKXs9M67rbZ62k0cBU4MVeyq4F1kbE/Wn9rWSJ4xUiYhmwDGDhwoWxaNGiPsLtXmNjIwMtOxy5Pjq5LrpyfXQaSF1s37WH9Xfewfv+5GgWLTo2n8AGSSWjqs4CFgOtEfEh4PVkX/B9eRCYJ2lO6sReCpQ/q3w5cG7Jee6KiEjrl6ZRV3OAecADEdEKrJE0P5VZjGfqNbNhoGV9OxFD9+FNpSppqtoeEXsldUg6AFhP16uBbqU+iwuBO4EG4PqIeFLSZcBDEbEcuA64MXV+v0SWXEj7/ZgsKXQAF6QRVZA9WOpHKRmtAj7UnzdsZjYU7RtRNYSnUy+qJHE8JOlAsmnWHwbagd9WcvCIWEHWvFW67tKS5R3A2T2UvRy4vJv1jwELKzm/mVm9aG4rMHb0KI46eOjfYdBn4oiIv0mL35N0B3BARDyeb1hmZiNLc1uBuYdOZnTD0J/Qo88IJf2yuBwRqyPi8dJ1Zma2/7I5qob2VCNFvd05Pp7sruxDJB1E53M5DiC7p8LMzAbByzt28/yWHXXRvwG9N1X9d+DjZFN+lE4v8jJwVY4xmZmNKCtTx3g9jKiC3u8cvxK4UtJHI+J/VzEmM7MRpam1HRj6c1QVVTKq6hpJHyObIwqgEbgmInbnFpWZ2QjS3FZg0tgGZhw4odahVKSSxPEdYEz6F+CDwHeBv84rKDOzkaS5rcDc6VMYNUp97zwE9NY5PjoiOoCTIuL1JZvukvS7/EMzMxsZmtsKvPXVh9U6jIr1Nhz3gfTvHknHFFdKOhrY030RMzPrj43tO9nYvqtu+jeg96aq4jXTp4G7Ja1Kr2fjaT7MzAZFc3FEVZ0MxYXeE8ehkj6Zlq8hm28KsquN44G78wzMzGwkWNmWjaiql6G40HviaAAm03nlUVqmft6hmdkQ1tRWYOqEMRw6ZVytQ6lYb4njhYi4rGqRmJmNQM2tBeZPn0L21Oz60FvneP28CzOzOhQRNLUVOPbw+pijqqi3xLG4alGYmY1ArS/voLCjo676N6CXxBERL1UzEDOzkaa5rb6mGika+hO/m5kNU82t6al/ThxmZlaJprYCh04Zx0GTxtY6lH5x4jAzq5HmtkLd9W+AE4eZWU3s3RusbGuvu2YqyDlxSDpdUpOkFkkXd7N9nKRb0vb7Jc0u2XZJWt8k6bSycg2SHpX0b3nGb2aWl7WbtrN99x7m19lQXMgxcUhqAK4GzgAWAO+TtKBst/OATRExF7gC+EYquwBYChwHnA58Jx2v6CLg6bxiNzPLW1Oao2qerzi6OBloiYhVEbELuBlYUrbPEuCGtHwrsFjZ7ZNLgJsjYmdEPAu0pOMhaSbwDuDaHGM3M8tVcXLDeYfV3xVHJQ9yGqgZwJqS12uBU3raJyI6JG0BpqX195WVnZGWvwV8lj7my5J0PnA+wPTp02lsbBzIe6C9vX3AZYcj10cn10VXro9OldTFrx/fwbTx4uH7flOdoAZRnolj0El6J7A+Ih6WtKi3fSNiGbAMYOHChbFoUa+796ixsZGBlh2OXB+dXBdduT46VVIXX3/sV7x+9gQWLTqpOkENojybqtYBs0pez0zrut1H0mhgKvBiL2VPBd4taTVZ09dbJf0wj+DNzPKye89eVm3YWpcjqiDfxPEgME/SHEljyTq7l5ftsxw4Ny2fBdwVEZHWL02jruYA84AHIuKSiJgZEbPT8e6KiA/k+B7MzAbdcy9uZdeevRw7vf76NyDHpqrUZ3EhcCfZsz2uj4gnJV0GPBQRy4HrgBsltQAvkSUD0n4/Bp4COoALIsKPqzWzYaGptT7nqCrKtY8jIlYAK8rWXVqyvAM4u4eylwOX93LsRqBxMOI0M6umprYCowRz63BEFfjOcTOzqlvZVmD2tEmMH9PQ985DkBOHmVmVNbUV6raZCpw4zMyqasfuPazeuLVuO8bBicPMrKp+v6GdvQHHHu4rDjMzq0BxqpF6nE69yInDzKyKmtvaGdMgZh8yqdahDJgTh5lZFTW3Fjjm0MmMaajfr9/6jdzMrA41tRXqcir1Uk4cZmZV0r6zg7WbtjO/jkdUgROHmVnVrEwd4/V8Dwc4cZiZVc3KtmyOqvl1PBQXnDjMzKqmqa3A+DGjmHXQxFqHsl+cOMzMqqS5rcC8w6YwapRqHcp+ceIwM6uSptb6nqOqyInDzKwKNm/bxfrCTuYfXt8jqsCJw8ysKprb6vvhTaWcOMzMqqCpOEdVnY+oAicOM7OqaG4tMGXcaA4/YHytQ9lvThxmZlXQ1Fbg2MOnINX3iCrIOXFIOl1Sk6QWSRd3s32cpFvS9vslzS7Zdkla3yTptLRulqS7JT0l6UlJF+UZv5nZYIgImuv8qX+lcksckhqAq4EzgAXA+yQtKNvtPGBTRMwFrgC+kcouAJYCxwGnA99Jx+sAPhURC4A3Ahd0c0wzsyFlQ/tONm/bXfdzVBXlecVxMtASEasiYhdwM7CkbJ8lwA1p+VZgsbLruCXAzRGxMyKeBVqAkyPihYh4BCAiCsDTwIwc34OZ2X5rbh0+I6oARud47BnAmpLXa4FTetonIjokbQGmpfX3lZXtkiBSs9bxwP3dnVzS+cD5ANOnT6exsXFAb6K9vX3AZYcj10cn10VXro9O5XVx5+rdAGz8/RM0rq3/Po48E0duJE0G/gX4eES83N0+EbEMWAawcOHCWLRo0YDO1djYyEDLDkeuj06ui65cH53K6+Lfb32caZPaePdp/6V2QQ2iPJuq1gGzSl7PTOu63UfSaGAq8GJvZSWNIUsaP4qI23KJ3MxsEDWvHz4d45Bv4ngQmCdpjqSxZJ3dy8v2WQ6cm5bPAu6KiEjrl6ZRV3OAecADqf/jOuDpiPhmjrGbmQ2KiKC5tTAsbvwryq2pKvVZXAjcCTQA10fEk5IuAx6KiOVkSeBGSS3AS2TJhbTfj4GnyEZSXRAReyS9Cfgg8ISkx9KpPh8RK/J6H2Zm+2Pd5u1s3bWHecNkRBXk3MeRvtBXlK27tGR5B3B2D2UvBy4vW3cvUP89S2Y2YjQXpxpxU5WZmVWiKQ3FnefEYWZmlVjZVuBVU8czdcKYWocyaJw4zMxy1DSMphopcuIwM8vJnr3ByvXtHDuMOsbBicPMLDfPvbiVXR17fcVhZmaVaR5GD28q5cRhZpaT5rZ2JJh7mJuqzMysAk1tBY48eCITx9bltIA9cuIwM8tJc2uBeYcNr2YqcOIwM8vFzo49PLtxK/MPH17NVODEYWaWi2c3bqVjbwy7EVXgxGFmlovmtmyqkeE2ogqcOMzMctHcWmD0KHH0IW6qMjOzCjS1FZh9yCTGjh5+X7PD7x2ZmQ0BzW2FYTWVeiknDjOzQbZzT/CHl7YNy45xcOIwMxt0L7TvJYJhORQXnDjMzAbd2va9AL7iMDOzyqwtBGNHj+KoaZNqHUounDjMzAbZuva9zD10Mg2jVOtQcpHrzFuSTgeuBBqAayPi62XbxwE/AE4EXgTOiYjVadslwHnAHuBjEXFnJcccLLc/uo7/dWcT6zZvZ8Z9d/GZ0+Zz5vEz8jhVRXE8v3k7Rxw4oeZx1LI+XBfdx+H66BpHLeujsy72MGHMVm5/dF1N6iJvuSUOSQ3A1cDbgbXAg5KWR8RTJbudB2yKiLmSlgLfAM6RtABYChwHHAH8QtKxqUxfx9xvtz+6jktue4Ltu/cAsG7zdi657QmAqn4IHMfQisFxOI7+xLB9956a1EU1KCLyObD0x8BXIuK09PoSgIj4u5J97kz7/FbSaKAVOBS4uHTf4n6pWK/H7M7ChQvjoYceqjj2U79+F+s2b3/F+tGjxJxDqtdmWZzrxnEMjRgch+MYSAwzDpzAby5+a1ViGGySHo6IheXr82yqmgGsKXm9Fjilp30iokPSFmBaWn9fWdliyu7rmABIOh84H2D69Ok0NjZWHHh3SQOgY28wVd1vy0N3H8KRGsdQiMFxOI6BxLBu8/Z+ff/Ug+H1dJESEbEMWAbZFceiRYsqLjvjvu6vOGYcOIFbP1G9vxx6uvIZiXEMhRgch+MYaAz9+f6pB3mOqloHzCp5PTOt63af1FQ1layTvKeylRxzv33mtPlMGNPQZd2EMQ185rT5g30qx1FHMTgOxzHUY6iWPK84HgTmSZpD9uW+FHh/2T7LgXOB3wJnAXdFREhaDvyzpG+SdY7PAx4AVMEx91uxI2vfSJEajdAojaOWI0WGQn24LnqOw/UxNOpjqNRFVUREbj/AnwPNwO+BL6R1lwHvTsvjgZ8ALWSJ4eiSsl9I5ZqAM3o7Zl8/J554YgzU3XffPeCyw5Hro5ProivXR6fhUhfAQ9HNd2qufRwRsQJYUbbu0pLlHcDZPZS9HLi8kmOamVn1+M5xMzPrFycOMzPrFycOMzPrFycOMzPrl9ymHBlKJG0Anhtg8UOAjYMYTr1zfXRyXXTl+ug0XOriqIg4tHzliEgc+0PSQ9HNXC0jleujk+uiK9dHp+FeF26qMjOzfnHiMDOzfnHi6NuyWgcwxLg+OrkuunJ9dBrWdeE+DjMz6xdfcZiZWb84cZiZWb84cfRA0umSmiS1SLq41vHUkqRZku6W9JSkJyVdVOuYhgJJDZIelfRvtY6lliQdKOlWSc9Iejo9NnrEkvSJ9Hvyn5JukjS+1jENNieObkhqAK4GzgAWAO+TtKC2UdVUB/CpiFgAvBG4YITXR9FFwNO1DmIIuBK4IyJeDbyeEVwnkmYAHwMWRsRrgQay5wYNK04c3TsZaImIVRGxC7gZWFLjmGomIl6IiEfScoHsi2EYPp2mcpJmAu8Arq11LLUkaSrwp8B1ABGxKyI21zSo2hsNTEhPNZ0IPF/jeAadE0f3ZgBrSl6vZYR/URZJmg0cD9xf41Bq7VvAZ4G9NY6j1uYAG4D/k5rtrpU0qdZB1UpErAP+AfgD8AKwJSJ+XtuoBp8Th1VM0mTgX4CPR8TLtY6nViS9E1gfEQ/XOpYhYDRwAvDdiDge2AqM2D5BSQeRtU7MIXvs9SRJH6htVIPPiaN764BZJa9npnUjlqQxZEnjRxFxW63jqbFTgXdLWk3WjPlWST+sbUg1sxZYGxHFK9BbyRLJSPU24NmI2BARu4HbgD+pcUyDzomjew8C8yTNkTSWrHNreY1jqhlJImvDfjoivlnreGotIi6JiJkRMZvss3FXRAy7vyorERGtwBpJ89OqxcBTNQyp1v4AvFHSxPR7s5hhOFgg12eO16uI6JB0IXAn2aiI6yPiyRqHVUunAh8EnpD0WFr3+fT8d7OPAj9Kf2StAj5U43hqJiLul3Qr8AjZaMRHGYbTj3jKETMz6xc3VZmZWb84cZiZWb84cZiZWb84cZiZWb84cZiZWb84cZgNgKQ9kh4r+en1bmlJH5H0l4Nw3tWSDtnf45jtDw/HNRsASe0RMbkG511NNvPqxmqf26zIVxxmgyhdEfy9pCckPSBpblr/FUmfTssfS882eVzSzWndwZJuT+vuk/S6tH6apJ+n5ztcC6jkXB9I53hM0jXpcQBmuXPiMBuYCWVNVeeUbNsSEX8EXEU2i265i4HjI+J1wEfSur8FHk3rPg/8IK3/MnBvRBwH/CtwJICk1wDnAKdGxBuAPcBfDOYbNOuJpxwxG5jt6Qu7OzeV/HtFN9sfJ5ui43bg9rTuTcB7ASLirnSlcQDZsy7ek9b/TNKmtP9i4ETgwWxKJCYA6/fj/ZhVzInDbPBFD8tF7yBLCO8CviDpjwZwDgE3RMQlAyhrtl/cVGU2+M4p+fe3pRskjQJmRcTdwOeAqcBk4NekpiZJi4CN6ZknvwLen9afARyUDvVL4CxJh6VtB0s6Kr+3ZNbJVxxmAzOhZKZgyJ65XRySe5Ckx4GdwPvKyjUAP0yPXBXw7YjYLOkrwPWp3Dbg3LT/3wI3SXoS+A+yabuJiKckfRH4eUpGu4ELgOcG+X2avYKH45oNIg+XtZHATVVmZtYvvuIwM7N+8RWHmZn1ixOHmZn1ixOHmZn1ixOHmZn1ixOHmZn1y/8P8S9fUly9JkQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "# 1) Create the wide DataFrame\n",
    "df_wide = create_wide_dataframe(data_url, limit_rows = 3000000)\n",
    "\n",
    "# Optionally limit to the first 1000 rows for faster experiments:\n",
    "#df_wide = df_wide.head(1000).copy()\n",
    "\n",
    "# 2) Convert df_wide to adjacency matrices\n",
    "rate_matrices, time_steps, currency_list = build_rate_matrices(df_wide)\n",
    "\n",
    "# Suppose you already built df_wide, rate_matrices, time_steps, currency_list\n",
    "# from your code above. Now create the environment:\n",
    "\n",
    "env_instance = ForexTradingEnv(\n",
    "    rate_matrices,\n",
    "    currency_list,\n",
    "    base_currency='USD',\n",
    "    max_steps_per_episode=1000  # or 2000, etc.\n",
    ")\n",
    "\n",
    "env = DummyVecEnv([lambda: env_instance])\n",
    "\n",
    "model = DQN(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    learning_rate=1e-4,               # Lower LR for possibly more stable training\n",
    "    buffer_size=200000,               # Larger replay buffer\n",
    "    batch_size=128,                   # Larger batch size\n",
    "    exploration_fraction=0.2,         # Explore more for longer\n",
    "    exploration_final_eps=0.01,       # End with lower epsilon\n",
    "    policy_kwargs={\"net_arch\": [256, 256]},  # Bigger network\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Increase total timesteps so it sees many episodes\n",
    "model.learn(total_timesteps=500000)  # half a million steps\n",
    "\n",
    "# Evaluate or do a custom run:\n",
    "def evaluate_agent(env, model, n_episodes=5):\n",
    "    rewards = []\n",
    "    for ep in range(n_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        ep_r = 0.0\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            ep_r += reward[0]  # for DummyVecEnv\n",
    "        rewards.append(ep_r)\n",
    "    return rewards\n",
    "\n",
    "episode_rewards = evaluate_agent(env, model, n_episodes=10)\n",
    "print(\"Episode Rewards:\", episode_rewards)\n",
    "\n",
    "# Plot them\n",
    "plt.figure()\n",
    "plt.plot(episode_rewards, marker='o')\n",
    "plt.title(\"Final Episode Rewards (Deterministic Policy)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminzaidel/opt/anaconda3/envs/ALL_PYTHON/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:77: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.21967697], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        1.5005842 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0031\n",
      "[DEBUG] final reward=0.0031\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 1.0059167 0.       ], final_val_base=1.0059\n",
      "[DEBUG] final reward=0.0059\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.9853067 0.       ], final_val_base=0.9853\n",
      "[DEBUG] final reward=-0.0147\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1503     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.154    |\n",
      "|    n_updates        | 1974     |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.2221228], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.       0.       0.       0.       0.       0.       0.       1.003572\n",
      " 0.      ], final_val_base=1.0036\n",
      "[DEBUG] final reward=0.0036\n",
      "[DEBUG] final portfolio: [0.        1.5068102 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0073\n",
      "[DEBUG] final reward=0.0073\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22145866], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1421     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.06     |\n",
      "|    n_updates        | 3974     |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6660882 0.        0.\n",
      " 0.        0.       ], final_val_base=1.0005\n",
      "[DEBUG] final reward=0.0005\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6629053 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9957\n",
      "[DEBUG] final reward=-0.0043\n",
      "[DEBUG] final portfolio: [0.        1.4684651 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9817\n",
      "[DEBUG] final reward=-0.0183\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6636045 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9967\n",
      "[DEBUG] final reward=-0.0033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1306     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.125    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.       0.       1.604287 0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=0.9983\n",
      "[DEBUG] final reward=-0.0017\n",
      "[DEBUG] final portfolio: [1.7940698 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0084\n",
      "[DEBUG] final reward=0.0084\n",
      "[DEBUG] final portfolio: [1.7735683 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9969\n",
      "[DEBUG] final reward=-0.0031\n",
      "[DEBUG] final portfolio: [0.        0.        1.5786467 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9824\n",
      "[DEBUG] final reward=-0.0176\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1293     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 7974     |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [  0.         0.         0.         0.         0.       112.909065\n",
      "   0.         0.         0.      ], final_val_base=0.9880\n",
      "[DEBUG] final reward=-0.0120\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0630693 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      113.00382   0.\n",
      "   0.        0.     ], final_val_base=0.9888\n",
      "[DEBUG] final reward=-0.0112\n",
      "[DEBUG] final portfolio: [0.       0.       0.       0.       0.       0.       0.       0.999266\n",
      " 0.      ], final_val_base=0.9993\n",
      "[DEBUG] final reward=-0.0007\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1279     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0946   |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        1.4673345 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9809\n",
      "[DEBUG] final reward=-0.0191\n",
      "[DEBUG] final portfolio: [0.       1.508016 0.       0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=1.0081\n",
      "[DEBUG] final reward=0.0081\n",
      "[DEBUG] final portfolio: [0.       0.       0.       1.062538 0.       0.       0.       0.\n",
      " 0.      ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        1.6250601 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0112\n",
      "[DEBUG] final reward=0.0112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1278     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0804   |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.65777767 0.\n",
      " 0.         0.         0.        ], final_val_base=0.9880\n",
      "[DEBUG] final reward=-0.0120\n",
      "[DEBUG] final portfolio: [  0.         0.         0.         0.         0.       112.218704\n",
      "   0.         0.         0.      ], final_val_base=0.9820\n",
      "[DEBUG] final reward=-0.0180\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6762313 0.        0.\n",
      " 0.        0.       ], final_val_base=1.0157\n",
      "[DEBUG] final reward=0.0157\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 1.0135553 0.       ], final_val_base=1.0136\n",
      "[DEBUG] final reward=0.0136\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1276     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 56000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0497   |\n",
      "|    n_updates        | 13974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        1.4993148 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0023\n",
      "[DEBUG] final reward=0.0023\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6602841 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9917\n",
      "[DEBUG] final reward=-0.0083\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.66360307 0.\n",
      " 0.         0.         0.        ], final_val_base=0.9967\n",
      "[DEBUG] final reward=-0.0033\n",
      "[DEBUG] final portfolio: [0.        0.        1.6008966 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9962\n",
      "[DEBUG] final reward=-0.0038\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1275     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 64000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0856   |\n",
      "|    n_updates        | 15974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        1.4935646 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9984\n",
      "[DEBUG] final reward=-0.0016\n",
      "[DEBUG] final portfolio: [1.7796613 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0003\n",
      "[DEBUG] final reward=0.0003\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.66596216 0.\n",
      " 0.         0.         0.        ], final_val_base=1.0003\n",
      "[DEBUG] final reward=0.0003\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.9952601 0.       ], final_val_base=0.9953\n",
      "[DEBUG] final reward=-0.0047\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1276     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0584   |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        1.4986602 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0018\n",
      "[DEBUG] final reward=0.0018\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0788089 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [1.7707201 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9953\n",
      "[DEBUG] final reward=-0.0047\n",
      "[DEBUG] final portfolio: [1.80622 0.      0.      0.      0.      0.      0.      0.      0.     ], final_val_base=1.0153\n",
      "[DEBUG] final reward=0.0153\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1273     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0356   |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [1.7718266 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9959\n",
      "[DEBUG] final reward=-0.0041\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.9851878 0.       ], final_val_base=0.9852\n",
      "[DEBUG] final reward=-0.0148\n",
      "[DEBUG] final portfolio: [1.7805762 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0009\n",
      "[DEBUG] final reward=0.0009\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0537452 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1272     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 88000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0458   |\n",
      "|    n_updates        | 21974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [1.7970977 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0101\n",
      "[DEBUG] final reward=0.0101\n",
      "[DEBUG] final portfolio: [0.       0.       1.620606 0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=1.0085\n",
      "[DEBUG] final reward=0.0085\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0659405 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6665186 0.        0.\n",
      " 0.        0.       ], final_val_base=1.0011\n",
      "[DEBUG] final reward=0.0011\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1273     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 96000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0815   |\n",
      "|    n_updates        | 23974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.       1.474272 0.       0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=0.9855\n",
      "[DEBUG] final reward=-0.0145\n",
      "[DEBUG] final portfolio: [0.       0.       0.       0.       0.668788 0.       0.       0.\n",
      " 0.      ], final_val_base=1.0045\n",
      "[DEBUG] final reward=0.0045\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0771648 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [1.7812873 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0013\n",
      "[DEBUG] final reward=0.0013\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 1272     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 104000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0595   |\n",
      "|    n_updates        | 25974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.21881838], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.65594614 0.\n",
      " 0.         0.         0.        ], final_val_base=0.9852\n",
      "[DEBUG] final reward=-0.0148\n",
      "[DEBUG] final portfolio: [1.7724211 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9963\n",
      "[DEBUG] final reward=-0.0037\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      115.12485   0.\n",
      "   0.        0.     ], final_val_base=1.0074\n",
      "[DEBUG] final reward=0.0074\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 1273     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 112000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0644   |\n",
      "|    n_updates        | 27974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      112.81661   0.\n",
      "   0.        0.     ], final_val_base=0.9872\n",
      "[DEBUG] final reward=-0.0128\n",
      "[DEBUG] final portfolio: [0.        1.5058795 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0067\n",
      "[DEBUG] final reward=0.0067\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6662735 0.        0.\n",
      " 0.        0.       ], final_val_base=1.0007\n",
      "[DEBUG] final reward=0.0007\n",
      "[DEBUG] final portfolio: [1.7699916 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9949\n",
      "[DEBUG] final reward=-0.0051\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 1272     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0686   |\n",
      "|    n_updates        | 29974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        1.5062569 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0069\n",
      "[DEBUG] final reward=0.0069\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.98571634 0.        ], final_val_base=0.9857\n",
      "[DEBUG] final reward=-0.0143\n",
      "[DEBUG] final portfolio: [0.        1.4958663 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0000\n",
      "[DEBUG] final reward=-0.0000\n",
      "[DEBUG] final portfolio: [1.7841597 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0029\n",
      "[DEBUG] final reward=0.0029\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 1270     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 128000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.076    |\n",
      "|    n_updates        | 31974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.9980795 0.       ], final_val_base=0.9981\n",
      "[DEBUG] final reward=-0.0019\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0615819 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        1.6407301 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0210\n",
      "[DEBUG] final reward=0.0210\n",
      "[DEBUG] final portfolio: [1.7661352 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9927\n",
      "[DEBUG] final reward=-0.0073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 1271     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 136000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0578   |\n",
      "|    n_updates        | 33974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0553902 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.       1.497485 0.       0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=1.0011\n",
      "[DEBUG] final reward=0.0011\n",
      "[DEBUG] final portfolio: [1.7981114 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0107\n",
      "[DEBUG] final reward=0.0107\n",
      "[DEBUG] final portfolio: [0.        1.4909811 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9967\n",
      "[DEBUG] final reward=-0.0033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 1271     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 144000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0617   |\n",
      "|    n_updates        | 35974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [1.7765173 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9986\n",
      "[DEBUG] final reward=-0.0014\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6691201 0.        0.\n",
      " 0.        0.       ], final_val_base=1.0050\n",
      "[DEBUG] final reward=0.0050\n",
      "[DEBUG] final portfolio: [1.8066505 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0155\n",
      "[DEBUG] final reward=0.0155\n",
      "[DEBUG] final portfolio: [1.7904131 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0064\n",
      "[DEBUG] final reward=0.0064\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 1271     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 152000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0343   |\n",
      "|    n_updates        | 37974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        1.4919001 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9973\n",
      "[DEBUG] final reward=-0.0027\n",
      "[DEBUG] final portfolio: [0.        1.4664294 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9803\n",
      "[DEBUG] final reward=-0.0197\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0489068 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0726403 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 1272     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0705   |\n",
      "|    n_updates        | 39974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        1.5988264 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9949\n",
      "[DEBUG] final reward=-0.0051\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0791001 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.66914964 0.\n",
      " 0.         0.         0.        ], final_val_base=1.0051\n",
      "[DEBUG] final reward=0.0051\n",
      "[DEBUG] final portfolio: [1.7917243 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0071\n",
      "[DEBUG] final reward=0.0071\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 1273     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 168000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.068    |\n",
      "|    n_updates        | 41974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0587803 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6596198 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9907\n",
      "[DEBUG] final reward=-0.0093\n",
      "[DEBUG] final portfolio: [0.        0.        1.6072024 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0001\n",
      "[DEBUG] final reward=0.0001\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.98830104 0.        ], final_val_base=0.9883\n",
      "[DEBUG] final reward=-0.0117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 1272     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 176000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.201    |\n",
      "|    n_updates        | 43974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.9853452 0.       ], final_val_base=0.9853\n",
      "[DEBUG] final reward=-0.0147\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6685314 0.        0.\n",
      " 0.        0.       ], final_val_base=1.0041\n",
      "[DEBUG] final reward=0.0041\n",
      "[DEBUG] final portfolio: [0.        0.        1.5911288 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9901\n",
      "[DEBUG] final reward=-0.0099\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      114.54684   0.\n",
      "   0.        0.     ], final_val_base=1.0023\n",
      "[DEBUG] final reward=0.0023\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 1273     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 184000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0424   |\n",
      "|    n_updates        | 45974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [1.8000145 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0118\n",
      "[DEBUG] final reward=0.0118\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.2220118], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22258803], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        1.5726042 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9786\n",
      "[DEBUG] final reward=-0.0214\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 1270     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 192000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0821   |\n",
      "|    n_updates        | 47974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22340992], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [1.764414 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=0.9918\n",
      "[DEBUG] final reward=-0.0082\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22172949], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.99459934 0.        ], final_val_base=0.9946\n",
      "[DEBUG] final reward=-0.0054\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 1265     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0618   |\n",
      "|    n_updates        | 49974    |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.    1.499 0.    0.    0.    0.    0.    0.    0.   ], final_val_base=1.0021\n",
      "[DEBUG] final reward=0.0021\n",
      "Total reward (deterministic) after training: 0.0041446685791015625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# 1) Create the wide DataFrame\n",
    "df_wide = create_wide_dataframe(data_url, limit_rows = 1000000)\n",
    "\n",
    "# Optionally limit to the first 1000 rows for faster experiments:\n",
    "#df_wide = df_wide.head(1000).copy()\n",
    "\n",
    "# 2) Convert df_wide to adjacency matrices\n",
    "rate_matrices, time_steps, currency_list = build_rate_matrices(df_wide)\n",
    "\n",
    "# 3) Create an instance of your environment\n",
    "env_instance = ForexTradingEnv(rate_matrices, currency_list, base_currency='USD')\n",
    "\n",
    "# 4) Wrap the environment in a DummyVecEnv so SB3 can handle it\n",
    "env = DummyVecEnv([lambda: env_instance])\n",
    "\n",
    "# 5) Instantiate a DQN model\n",
    "model = DQN(\n",
    "    policy=\"MlpPolicy\",    # Use a simple MLP\n",
    "    env=env,\n",
    "    learning_rate=1e-4,\n",
    "    buffer_size=50000,\n",
    "    batch_size=64,\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_final_eps=0.02,\n",
    "    verbose=1,\n",
    "    #tensorboard_log=\"./dqn_fx_log\"  # optional, for TensorBoard\n",
    ")\n",
    "\n",
    "# 6) Train the model\n",
    "model.learn(total_timesteps=200000)  # adjust as needed\n",
    "\n",
    "# 7) Evaluate or test the trained model\n",
    "obs = env.reset()\n",
    "done = False\n",
    "total_reward = 0.0\n",
    "\n",
    "while True:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    total_reward += reward[0]  # stable-baselines uses vectorized env, so reward is array-like\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"Total reward (deterministic) after training:\", total_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminzaidel/opt/anaconda3/envs/ALL_PYTHON/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 5 episodes: mean_reward=-2.00 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Suppose 'model' is your trained DQN and 'env' is your DummyVecEnv\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=5, render=False)\n",
    "\n",
    "print(f\"Evaluation over 5 episodes: mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.67279744 0.\n",
      " 0.         0.         0.        ], final_val_base=1.0105\n",
      "[DEBUG] final reward=0.0105\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.9999781 0.       ], final_val_base=1.0000\n",
      "[DEBUG] final reward=-0.0000\n",
      "[DEBUG] final portfolio: [0.       0.       0.       0.       0.       0.       0.       1.007399\n",
      " 0.      ], final_val_base=1.0074\n",
      "[DEBUG] final reward=0.0074\n",
      "[DEBUG] final portfolio: [0.       0.       0.       1.063646 0.       0.       0.       0.\n",
      " 0.      ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1358     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0619   |\n",
      "|    n_updates        | 154187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.99588037 0.        ], final_val_base=0.9959\n",
      "[DEBUG] final reward=-0.0041\n",
      "[DEBUG] final portfolio: [  0.         0.         0.         0.         0.       114.867455\n",
      "   0.         0.         0.      ], final_val_base=1.0051\n",
      "[DEBUG] final reward=0.0051\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22137779], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [1.7669122 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9932\n",
      "[DEBUG] final reward=-0.0068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1398     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0484   |\n",
      "|    n_updates        | 156187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6676304 0.        0.\n",
      " 0.        0.       ], final_val_base=1.0028\n",
      "[DEBUG] final reward=0.0028\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.65844184 0.\n",
      " 0.         0.         0.        ], final_val_base=0.9890\n",
      "[DEBUG] final reward=-0.0110\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      112.75396   0.\n",
      "   0.        0.     ], final_val_base=0.9866\n",
      "[DEBUG] final reward=-0.0134\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22222222], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1379     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0505   |\n",
      "|    n_updates        | 158187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [1.796149 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=1.0096\n",
      "[DEBUG] final reward=0.0096\n",
      "[DEBUG] final portfolio: [0.        0.        1.6252362 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0113\n",
      "[DEBUG] final reward=0.0113\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      113.65622   0.\n",
      "   0.        0.     ], final_val_base=0.9945\n",
      "[DEBUG] final reward=-0.0055\n",
      "[DEBUG] final portfolio: [0.       0.       0.       0.       0.       0.       0.       1.000267\n",
      " 0.      ], final_val_base=1.0003\n",
      "[DEBUG] final reward=0.0003\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1355     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0547   |\n",
      "|    n_updates        | 160187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.99604285 0.        ], final_val_base=0.9960\n",
      "[DEBUG] final reward=-0.0040\n",
      "[DEBUG] final portfolio: [1.7945873 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0087\n",
      "[DEBUG] final reward=0.0087\n",
      "[DEBUG] final portfolio: [0.        0.        1.6221386 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0094\n",
      "[DEBUG] final reward=0.0094\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0593556 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1343     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0381   |\n",
      "|    n_updates        | 162187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.99126214 0.        ], final_val_base=0.9913\n",
      "[DEBUG] final reward=-0.0087\n",
      "[DEBUG] final portfolio: [0.        1.4823617 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9909\n",
      "[DEBUG] final reward=-0.0091\n",
      "[DEBUG] final portfolio: [0.        0.        1.6159159 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0055\n",
      "[DEBUG] final reward=0.0055\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      112.11154   0.\n",
      "   0.        0.     ], final_val_base=0.9810\n",
      "[DEBUG] final reward=-0.0190\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1331     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0534   |\n",
      "|    n_updates        | 164187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6598534 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9911\n",
      "[DEBUG] final reward=-0.0089\n",
      "[DEBUG] final portfolio: [0.        0.        1.6010933 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9963\n",
      "[DEBUG] final reward=-0.0037\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.66600204 0.\n",
      " 0.         0.         0.        ], final_val_base=1.0003\n",
      "[DEBUG] final reward=0.0003\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.65780234 0.\n",
      " 0.         0.         0.        ], final_val_base=0.9880\n",
      "[DEBUG] final reward=-0.0120\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1321     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 56000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0731   |\n",
      "|    n_updates        | 166187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [  0.       0.       0.       0.       0.     112.1197   0.       0.\n",
      "   0.    ], final_val_base=0.9811\n",
      "[DEBUG] final reward=-0.0189\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6566966 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9864\n",
      "[DEBUG] final reward=-0.0136\n",
      "[DEBUG] final portfolio: [0.       1.476447 0.       0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=0.9870\n",
      "[DEBUG] final reward=-0.0130\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.9954495 0.       ], final_val_base=0.9954\n",
      "[DEBUG] final reward=-0.0046\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1307     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 64000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0425   |\n",
      "|    n_updates        | 168187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22003229], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        1.6320139 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0156\n",
      "[DEBUG] final reward=0.0156\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 1.0036893 0.       ], final_val_base=1.0037\n",
      "[DEBUG] final reward=0.0037\n",
      "[DEBUG] final portfolio: [0.       0.       1.619054 0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=1.0075\n",
      "[DEBUG] final reward=0.0075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1301     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.038    |\n",
      "|    n_updates        | 170187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.66681963 0.\n",
      " 0.         0.         0.        ], final_val_base=1.0016\n",
      "[DEBUG] final reward=0.0016\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6577432 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9879\n",
      "[DEBUG] final reward=-0.0121\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6771975 0.        0.\n",
      " 0.        0.       ], final_val_base=1.0172\n",
      "[DEBUG] final reward=0.0172\n",
      "[DEBUG] final portfolio: [0.    1.493 0.    0.    0.    0.    0.    0.    0.   ], final_val_base=0.9981\n",
      "[DEBUG] final reward=-0.0019\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1290     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0372   |\n",
      "|    n_updates        | 172187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.98969346 0.        ], final_val_base=0.9897\n",
      "[DEBUG] final reward=-0.0103\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.66248775 0.\n",
      " 0.         0.         0.        ], final_val_base=0.9951\n",
      "[DEBUG] final reward=-0.0049\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6580417 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9884\n",
      "[DEBUG] final reward=-0.0116\n",
      "[DEBUG] final portfolio: [  0.         0.         0.         0.         0.       114.508865\n",
      "   0.         0.         0.      ], final_val_base=1.0020\n",
      "[DEBUG] final reward=0.0020\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1279     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 88000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.259    |\n",
      "|    n_updates        | 174187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.99197173 0.        ], final_val_base=0.9920\n",
      "[DEBUG] final reward=-0.0080\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 1.0136639 0.       ], final_val_base=1.0137\n",
      "[DEBUG] final reward=0.0137\n",
      "[DEBUG] final portfolio: [0.        1.4855052 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9931\n",
      "[DEBUG] final reward=-0.0069\n",
      "[DEBUG] final portfolio: [0.        0.        1.6256955 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0116\n",
      "[DEBUG] final reward=0.0116\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1266     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 96000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 176187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 1.0002377 0.       ], final_val_base=1.0002\n",
      "[DEBUG] final reward=0.0002\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6627156 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9954\n",
      "[DEBUG] final reward=-0.0046\n",
      "[DEBUG] final portfolio: [1.7991031 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0113\n",
      "[DEBUG] final reward=0.0113\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.21978022], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 1253     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 104000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0565   |\n",
      "|    n_updates        | 178187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.9727987 0.       ], final_val_base=0.9728\n",
      "[DEBUG] final reward=-0.0272\n",
      "[DEBUG] final portfolio: [0.       0.       0.       0.       0.       0.       0.       1.000867\n",
      " 0.      ], final_val_base=1.0009\n",
      "[DEBUG] final reward=0.0009\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.66678846 0.\n",
      " 0.         0.         0.        ], final_val_base=1.0015\n",
      "[DEBUG] final reward=0.0015\n",
      "[DEBUG] final portfolio: [0.       0.       1.633352 0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=1.0164\n",
      "[DEBUG] final reward=0.0164\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 1248     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 112000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0657   |\n",
      "|    n_updates        | 180187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [1.7714081 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9957\n",
      "[DEBUG] final reward=-0.0043\n",
      "[DEBUG] final portfolio: [1.7478058 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9824\n",
      "[DEBUG] final reward=-0.0176\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6652507 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9992\n",
      "[DEBUG] final reward=-0.0008\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6682181 0.        0.\n",
      " 0.        0.       ], final_val_base=1.0037\n",
      "[DEBUG] final reward=0.0037\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 1252     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0453   |\n",
      "|    n_updates        | 182187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.       1.471182 0.       0.       0.       0.       0.       0.\n",
      " 0.      ], final_val_base=0.9835\n",
      "[DEBUG] final reward=-0.0165\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6643054 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9978\n",
      "[DEBUG] final reward=-0.0022\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.66624016 0.\n",
      " 0.         0.         0.        ], final_val_base=1.0007\n",
      "[DEBUG] final reward=0.0007\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6599996 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9913\n",
      "[DEBUG] final reward=-0.0087\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 1256     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 128000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0486   |\n",
      "|    n_updates        | 184187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      114.39627   0.\n",
      "   0.        0.     ], final_val_base=1.0010\n",
      "[DEBUG] final reward=0.0010\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6612471 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9932\n",
      "[DEBUG] final reward=-0.0068\n",
      "[DEBUG] final portfolio: [0.        1.4895517 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9958\n",
      "[DEBUG] final reward=-0.0042\n",
      "[DEBUG] final portfolio: [0.        1.4901634 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9962\n",
      "[DEBUG] final reward=-0.0038\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 1259     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 136000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0655   |\n",
      "|    n_updates        | 186187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        1.4515017 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9703\n",
      "[DEBUG] final reward=-0.0297\n",
      "[DEBUG] final portfolio: [1.7739297 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9971\n",
      "[DEBUG] final reward=-0.0029\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      113.59398   0.\n",
      "   0.        0.     ], final_val_base=0.9940\n",
      "[DEBUG] final reward=-0.0060\n",
      "[DEBUG] final portfolio: [0.        1.4983106 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0016\n",
      "[DEBUG] final reward=0.0016\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 1256     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 144000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0686   |\n",
      "|    n_updates        | 188187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        1.6034435 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9978\n",
      "[DEBUG] final reward=-0.0022\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6585473 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9891\n",
      "[DEBUG] final reward=-0.0109\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0653675 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      113.06417   0.\n",
      "   0.        0.     ], final_val_base=0.9894\n",
      "[DEBUG] final reward=-0.0106\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 1244     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 152000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0777   |\n",
      "|    n_updates        | 190187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.6577042 0.        0.\n",
      " 0.        0.       ], final_val_base=0.9879\n",
      "[DEBUG] final reward=-0.0121\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      113.44656   0.\n",
      "   0.        0.     ], final_val_base=0.9927\n",
      "[DEBUG] final reward=-0.0073\n",
      "[DEBUG] final portfolio: [0.        0.        1.6203507 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0083\n",
      "[DEBUG] final reward=0.0083\n",
      "[DEBUG] final portfolio: [0.        0.        1.6020291 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9969\n",
      "[DEBUG] final reward=-0.0031\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 1236     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0701   |\n",
      "|    n_updates        | 192187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        1.4948555 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9993\n",
      "[DEBUG] final reward=-0.0007\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0541458 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0717578 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      112.46769   0.\n",
      "   0.        0.     ], final_val_base=0.9841\n",
      "[DEBUG] final reward=-0.0159\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 1235     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 168000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0484   |\n",
      "|    n_updates        | 194187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.2204451], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.99299127 0.        ], final_val_base=0.9930\n",
      "[DEBUG] final reward=-0.0070\n",
      "[DEBUG] final portfolio: [1.7716339 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9958\n",
      "[DEBUG] final reward=-0.0042\n",
      "[DEBUG] final portfolio: [0.       0.       0.       0.       0.670789 0.       0.       0.\n",
      " 0.      ], final_val_base=1.0075\n",
      "[DEBUG] final reward=0.0075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 1239     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 176000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0507   |\n",
      "|    n_updates        | 196187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0727272 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        1.6448714 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0236\n",
      "[DEBUG] final reward=0.0236\n",
      "[DEBUG] final portfolio: [1.8008507 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0123\n",
      "[DEBUG] final reward=0.0123\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22263476], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 1235     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 184000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0502   |\n",
      "|    n_updates        | 198187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        1.6221769 0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=1.0094\n",
      "[DEBUG] final reward=0.0094\n",
      "[DEBUG] final portfolio: [0.        1.4945982 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9991\n",
      "[DEBUG] final reward=-0.0009\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.22050121], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        1.4692403 0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9822\n",
      "[DEBUG] final reward=-0.0178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 1230     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 192000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0307   |\n",
      "|    n_updates        | 200187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [1.7579643 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.9882\n",
      "[DEBUG] final reward=-0.0118\n",
      "[DEBUG] final portfolio: [  0.        0.        0.        0.        0.      114.11608   0.\n",
      "   0.        0.     ], final_val_base=0.9986\n",
      "[DEBUG] final reward=-0.0014\n",
      "[DEBUG] final portfolio: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.98459053 0.        ], final_val_base=0.9846\n",
      "[DEBUG] final reward=-0.0154\n",
      "[DEBUG] final portfolio: [0.        0.        0.        0.        0.        0.        0.\n",
      " 1.0016919 0.       ], final_val_base=1.0017\n",
      "[DEBUG] final reward=0.0017\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 1225     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0382   |\n",
      "|    n_updates        | 202187   |\n",
      "----------------------------------\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] final portfolio: [0.        0.        0.        1.0778773 0.        0.        0.\n",
      " 0.        0.       ], final_val_base=0.0000\n",
      "[DEBUG] final reward=-1.0000\n",
      "Final single-episode reward: -2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_agent(env, model, n_episodes=10):\n",
    "    \"\"\"\n",
    "    Runs n_episodes in a row, records final rewards,\n",
    "    returns a list of total rewards for each episode.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    for ep in range(n_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_r = 0.0\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            # reward is array-like for DummyVecEnv\n",
    "            total_r += reward[0]\n",
    "        rewards.append(total_r)\n",
    "    return rewards\n",
    "\n",
    "def run_single_episode(env, model):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    step_rewards = []\n",
    "    cum_rewards = []\n",
    "    total_r = 0.0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        step_r = reward[0]  # for vectorized env\n",
    "        total_r += step_r\n",
    "        step_rewards.append(step_r)\n",
    "        cum_rewards.append(total_r)\n",
    "    \n",
    "    return step_rewards, cum_rewards, total_r\n",
    "\n",
    "\n",
    "# 1) Train\n",
    "model.learn(total_timesteps=200000)\n",
    "\n",
    "# 2) Evaluate on 10 episodes\n",
    "episode_rewards = evaluate_agent(env, model, n_episodes=10)\n",
    "plt.figure()\n",
    "plt.plot(episode_rewards, marker='o')\n",
    "plt.title(\"Episode Rewards\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.show()\n",
    "\n",
    "# 3) Single-episode breakdown\n",
    "step_rewards, cum_rewards, final_r = run_single_episode(env, model)\n",
    "print(\"Final single-episode reward:\", final_r)\n",
    "window_size = 50\n",
    "smoothed_immediate = np.convolve(step_rewards, np.ones(window_size)/window_size, mode='valid')\n",
    "plt.plot(smoothed_immediate, label='Smoothed Immediate Reward')\n",
    "plt.figure()\n",
    "plt.plot(cum_rewards, label=\"Cumulative Reward\")\n",
    "plt.plot(step_rewards, label=\"Immediate Reward\", alpha=0.5)\n",
    "plt.title(\"Rewards Within a Single Episode\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALL_PYTHON",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
